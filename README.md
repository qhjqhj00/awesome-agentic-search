# ğŸ” Awesome Agentic Search

ğŸ¤– Agentic search refers to an advanced AI approach where autonomous agents plan and execute multi-step search processes to address complex queries. Unlike traditional search methods that provide static results, agentic search involves dynamic workflows where the AI agent decomposes a query, conducts iterative searches, evaluates information relevance, and synthesizes findings into coherent responses. This methodology enhances deep research capabilities, supports search-enhanced reasoning, and enables interleaved workflows, positioning AI agents as active researchers rather than passive information retrievers.


> ğŸš§ **Note**: This project is under intensive development and will be rapidly updated with new content, features and resources. We welcome you to join our community - please feel free to open issues, submit PRs, leave comments and â­ star the repo to show your support! Together we can build a comprehensive resource for advancing agentic search.

## ğŸ“š Papers
For each paper, we provide the following information:
 > ğŸ‘¨â€ğŸ“ **First Author** Â· ğŸ“§ **Corresponding Author (Last Author if not specified)** Â· ğŸ›ï¸ **First Organization** Â· ğŸ“Š **Dataset** 
 
  *Note: Please submit a PR if we missed anything!*

ğŸ“Š Dataset Types:

**General QA**: NQ, TriviaQA, PopQA

**Multi-Hop QA**: HotpotQA, 2wiki, Musique, Bamboogle

**Complex Task**: GPQA, GAIA, WebWalker QA, Humanity's Last Exam (HLE)

**Report Generation**: Glaive

**Math & Coding**: AIME, MATH500, AMC, LiveCodeBench

### ğŸ“ Training-based
[Search-R1: Training LLMs to Reason and Leverage Search
Engines with Reinforcement Learning](https://arxiv.org/abs/2503.09516) ![GitHub Repo stars](https://img.shields.io/github/stars/PeterGriffinJin/Search-R1?style=social)

 > ğŸ‘¨â€ğŸ“ **Bowen Jin** Â· ğŸ“§ **Jiawei Han** Â· ğŸ›ï¸ **UIUC** \
 > ğŸ“Š **Dataset**: General QA, Multi-Hop QA Â· ğŸ¤– **Model**: Qwen-2.5-3B / 7B Â· ğŸ¯ **Training**: GRPO, PPO


[WebThinker: Empowering Large Reasoning Models with Deep Research Capability](https://arxiv.org/abs/2504.21776):![GitHub Repo stars](https://img.shields.io/github/stars/RUC-NLPIR/WebThinker?style=social)

 > ğŸ‘¨â€ğŸ“ **Xiaoxi Li** Â· ğŸ“§ **Zhicheng Dou** Â· ğŸ›ï¸ **GSAI, RUC** \
 > ğŸ“Š **Dataset**: Complex Task, Report Generation Â· ğŸ¤– **Model**: QwQ 32B Â· ğŸ¯ **Training**: SFT, DPO


[DeepResearcher: Scaling Deep Research via Reinforcement Learning in Real-world Environments](https://arxiv.org/abs/2504.03160) [![[code]](https://img.shields.io/github/stars/GAIR-NLP/DeepResearcher)](https://github.com/GAIR-NLP/DeepResearcher)

 > ğŸ‘¨â€ğŸ“ **Yuxiang Zheng** Â· ğŸ“§ **Pengfei Liu** Â· ğŸ›ï¸ **SJTU** \
 > ğŸ“Š **Dataset**: General QA, Multi-Hop QA Â· ğŸ¤– **Model**: Qwen-2.5-7B Â· ğŸ¯ **Training**: GRPO


[R1-Searcher: Incentivizing the Search Capability in LLMs via Reinforcement Learning](https://arxiv.org/abs/2503.05592) [![[code]](https://img.shields.io/github/stars/RUCAIBox/R1-Searcher)](https://github.com/RUCAIBox/R1-Searcher)

 > ğŸ‘¨â€ğŸ“ **Huatong Song** Â· ğŸ“§ **Wayne Xin Zhao** Â· ğŸ›ï¸ **GSAI, RUC** \
 > ğŸ“Š **Dataset**: General QA, Multi-Hop QA Â· ğŸ¤– **Model**: Qwen-2.5-7B, Llama-3.1-8B Â· ğŸ¯ **Training**: SFT, GRPO, REINFORCE++

[ZeroSearch: Incentivize the Search Capability of LLMs without Searching](https://arxiv.org/abs/2505.04588) [![[code]](https://img.shields.io/github/stars/Alibaba-NLP/ZeroSearch)](https://github.com/Alibaba-NLP/ZeroSearch)

 > ğŸ‘¨â€ğŸ“ **Hao Sun** Â· ğŸ“§ **Zile Qiao, Jiayan Guo, Yan Zhang** Â· ğŸ›ï¸ **Tongyi Lab** \
 > ğŸ“Š **Dataset**: General QA, Multi-Hop QA Â· ğŸ¤– **Model**: Qwen-2.5-3B / 7B, s LLaMA-3.2-3B Â· ğŸ¯ **Training**: REINFORCE, GRPO, PPO

[Chain-of-Retrieval Augmented Generation](https://arxiv.org/abs/2501.14342) [![[code]](https://img.shields.io/github/stars/microsoft/LMOps)](https://github.com/microsoft/LMOps/)

 > ğŸ‘¨â€ğŸ“ **Liang Wang** Â· ğŸ“§ **Furu Wei** Â· ğŸ›ï¸ **MSRA** \
 > ğŸ“Š **Dataset**: General QA, Multi-Hop QA Â· ğŸ¤– **Model**: Llama-3.1-8B-Instruct Â· ğŸ¯ **Training**: REINFORCE, GRPO, PPO

[IKEA: Reinforced Internal-External Knowledge Synergistic Reasoning for Efficient Adaptive Search Agent](https://arxiv.org/abs/2505.07596) [![[code]](https://img.shields.io/github/stars/hzy312/knowledge-r1)](https://github.com/hzy312/knowledge-r1)

 > ğŸ‘¨â€ğŸ“ **Ziyang Huang** Â· ğŸ“§ **Kang Liu** Â· ğŸ›ï¸ **IA, CAS** \
 > ğŸ“Š **Dataset**: General QA, Multi-Hop QA Â· ğŸ¤– **Model**: Qwen-2.5-3B / 7B Â· ğŸ¯ **Training**: GRPO

[Scent of Knowledge: Optimizing Search-Enhanced Reasoning with Information Foraging](https://arxiv.org/abs/2505.09316)

> ğŸ‘¨â€ğŸ“ **Hongjin Qian** Â· ğŸ“§ **Zheng Liu** Â· ğŸ›ï¸ **BAAI** \
> ğŸ“Š **Dataset**: General QA, Multi-Hop QA Â· ğŸ¤– **Model**: Qwen-2.5-3B / 7B Â· ğŸ¯ **Training**: GRPO, PPO


[Search and Refine During Think: Autonomous Retrieval-Augmented Reasoning of LLMs](https://arxiv.org/pdf/2505.11277) [![[code]](https://img.shields.io/github/stars/syr-cn/AutoRefine)](https://github.com/syr-cn/AutoRefine)

> ğŸ‘¨â€ğŸ“ **Yaorui Shi** Â· ğŸ“§ **Xiang Wang** Â· ğŸ›ï¸ **USTC** \
> ğŸ“Š **Dataset**: General QA, Multi-Hop QA Â· ğŸ¤– **Model**: Qwen-2.5-3B Â· ğŸ¯ **Training**: GRPO



### ğŸ”„ Workflow-based
[Search-o1: Agentic Search-Enhanced Large Reasoning Models](https://arxiv.org/abs/2501.05366):  [![[code]](https://img.shields.io/github/stars/sunnynexus/Search-o1?style=social)](https://github.com/sunnynexus/Search-o1)

 > ğŸ‘¨â€ğŸ“ **Xiaoxi Li** Â· ğŸ“§ **Zhicheng Dou** Â· ğŸ›ï¸ **GSAI, RUC** \
 > ğŸ“Š **Dataset**: General QA, Multi-Hop QA, Complex Task, Math & Coding Â· ğŸ¤– **Model**: QwQ-32B-Preview

 [Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research](https://arxiv.org/pdf/2502.04644) [![[code]](https://img.shields.io/github/stars/theworldofagents/Agentic-Reasoning)](https://github.com/theworldofagents/Agentic-Reasoning)

> ğŸ‘¨â€ğŸ“ **Junde Wu** Â· ğŸ“§ **Yuyuan Liu** Â· ğŸ›ï¸ **Oxford University** \
> ğŸ“Š **Dataset**: Complex Task Â· ğŸ¤– **Model**: APIs


###  ğŸ”§ Tool Using
[OTC: Optimal Tool Calls via Reinforcement Learning](https://arxiv.org/pdf/2504.14870)

 > ğŸ‘¨â€ğŸ“ **Hongru Wang** Â· ğŸ“§ **Heng Ji** Â· ğŸ›ï¸ **CUHK** \
 > ğŸ“Š **Dataset**: General QA, Multi-Hop QA, Math & Coding Â· ğŸ¤– **Model**: Qwen-2.5-3B / 7BÂ· ğŸ¯ **Training**: GRPO, PPO

### ğŸ–¼ï¸ Multi-Modal
[Multimodal-Search-R1: Incentivizing LMMs to Search](https://kimingng.notion.site/MMSearch-R1-Incentivizing-LMMs-to-Search-1bcce992031880b2bc64fde13ef83e2a) [![[code]](https://img.shields.io/github/stars/EvolvingLMMs-Lab/multimodal-search-r1)](https://github.com/EvolvingLMMs-Lab/multimodal-search-r1)

 > ğŸ‘¨â€ğŸ“ **Jinming Wu** Â· ğŸ“§ **Zejun Ma** Â· ğŸ›ï¸ **BUPT** \
 > ğŸ“Š **Dataset**: VQA Â· ğŸ¤– **Model**: Qwen2.5-VL-Instruct-3B/7B Â· ğŸ¯ **Training**: GRPO

<!-- ### ğŸ“Š Evaluation and Dataset -->

### ğŸ¢ Industry Solutions

OpenAI's  Deep Research: https://openai.com/index/introducing-deep-research/

Google's Gemini Pro: https://www.google.com/search/about/

X's Grok 3: https://x.ai/news/grok-3

Perplexity: https://www.perplexity.ai/

Jina AI: https://jina.ai/deepsearch/

Metasota: https://metaso.cn/

## ğŸ“ Slides
We maintain a collection of ğŸ“Š paper presentation slides on Overleaf to facilitate learning and knowledge sharing in the agentic search community. Each presentation consists of 3-5 slides that concisely introduce key aspects of a paper, including motivation, methodology, and main results. These slides serve as quick references for understanding important works in the field and can be used for self-study, teaching, or research presentations.

ğŸ”— Check out our slides collection: [Agentic Search Paper Slides](https://www.overleaf.com/read/dhbksrdxswps#3990a3)

## ğŸ“Š Evaluation

We maintain a comprehensive evaluation table comparing different agentic search methods across key metrics like search efficiency, result quality, and reasoning capabilities. The table will be regularly updated as new methods and benchmarks emerge to help researchers track progress in the field.

## ğŸ† Arena
We are building an arena page to benchmark different agentic search methods using standardized retrieval and web browser interfaces. This will enable fair comparisons between various approaches and help advance the state-of-the-art in agentic search.

## ğŸ¤ Contributing
We welcome contributions to this repository! If you have any suggestions or feedback, please feel free to open an issue or submit a pull request.


## ğŸ“– Citation
If you find this repository useful, please consider citing it as follows:
```bibtex
@misc{awesome-agentic-search,
  author = {Hongjin Qian, Zheng Liu},
  title = {Awesome Agentic Search},
  year = {2025},
  publisher = {GitHub},
```